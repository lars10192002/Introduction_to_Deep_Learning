{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    #if IS_COLAB:\n",
    "        #print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images_dir = '/kaggle/input/herbarium-2020-fgvc7/nybg2020/train/'\n",
    "#test_images_dir = '/kaggle/input/herbarium-2020-fgvc7/nybg2020/test/'\n",
    "train_images_dir = './nybg2020/train/'\n",
    "test_images_dir = './nybg2020/test/'\n",
    "\n",
    "#train_metadata_file_path = '/kaggle/input/herbarium-2020-fgvc7/nybg2020/train/metadata.json'\n",
    "#test_metadata_file_path = '/kaggle/input/herbarium-2020-fgvc7/nybg2020/test/metadata.json'\n",
    "train_metadata_file_path = './nybg2020/train/metadata.json'\n",
    "test_metadata_file_path = './nybg2020/test/metadata.json'\n",
    "\n",
    "num_classes = 32093 + 1\n",
    "batch_size = 16\n",
    "\n",
    "steps_per_epoch = int(num_classes / batch_size)\n",
    "\n",
    "img_height = 1000\n",
    "img_width = 661\n",
    "\n",
    "epochs_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_metadata_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    train_metadata_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'categories', 'images', 'info', 'licenses', 'regions'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see presented keys\n",
    "train_metadata_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1030747 entries, 0 to 1030746\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   category_id    1030747 non-null  int32 \n",
      " 1   id             1030747 non-null  int32 \n",
      " 2   image_id       1030747 non-null  int32 \n",
      " 3   region_id      1030747 non-null  int32 \n",
      " 4   family         1030747 non-null  object\n",
      " 5   genus          1030747 non-null  object\n",
      " 6   category_name  1030747 non-null  object\n",
      " 7   file_name      1030747 non-null  object\n",
      " 8   height         1030747 non-null  int32 \n",
      " 9   license        1030747 non-null  int32 \n",
      " 10  width          1030747 non-null  int32 \n",
      " 11  region_name    1030747 non-null  object\n",
      "dtypes: int32(7), object(5)\n",
      "memory usage: 74.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Create Pandas DataFrame per each data type\n",
    "train_metadata = pd.DataFrame(train_metadata_json['annotations'])\n",
    "\n",
    "train_categories = pd.DataFrame(train_metadata_json['categories'])\n",
    "train_categories.columns = ['family', 'genus', 'category_id', 'category_name']\n",
    "\n",
    "train_images = pd.DataFrame(train_metadata_json['images'])\n",
    "train_images.columns = ['file_name', 'height', 'image_id', 'license', 'width']\n",
    "\n",
    "train_regions = pd.DataFrame(train_metadata_json['regions'])\n",
    "train_regions.columns = ['region_id', 'region_name']\n",
    "\n",
    "#Combine DataFrames\n",
    "train_data = train_metadata.merge(train_categories, on='category_id', how='outer')\n",
    "train_data = train_data.merge(train_images, on='image_id', how='outer')\n",
    "train_data = train_data.merge(train_regions, on='region_id', how='outer')\n",
    "\n",
    "#Remove NaN values\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "# Update data types\n",
    "train_data = train_data.astype({'category_id': 'int32',\n",
    "                                'id': 'int32',\n",
    "                                'image_id': 'int32',\n",
    "                                'region_id': 'int32',\n",
    "                                'height': 'int32',\n",
    "                                'license': 'int32',\n",
    "                                'width': 'int32'})\n",
    "\n",
    "train_data.info()\n",
    "\n",
    "#Save DataFrame for future usage.\n",
    "train_data.to_csv('train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_categories\n",
    "del train_images\n",
    "del train_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>category_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "      <th>region_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15672</td>\n",
       "      <td>354106</td>\n",
       "      <td>354106</td>\n",
       "      <td>1</td>\n",
       "      <td>Lecythidaceae</td>\n",
       "      <td>Lecythis</td>\n",
       "      <td>Lecythis retusa Spruce ex O.Berg</td>\n",
       "      <td>images/156/72/354106.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15672</td>\n",
       "      <td>545181</td>\n",
       "      <td>545181</td>\n",
       "      <td>1</td>\n",
       "      <td>Lecythidaceae</td>\n",
       "      <td>Lecythis</td>\n",
       "      <td>Lecythis retusa Spruce ex O.Berg</td>\n",
       "      <td>images/156/72/545181.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15672</td>\n",
       "      <td>449419</td>\n",
       "      <td>449419</td>\n",
       "      <td>1</td>\n",
       "      <td>Lecythidaceae</td>\n",
       "      <td>Lecythis</td>\n",
       "      <td>Lecythis retusa Spruce ex O.Berg</td>\n",
       "      <td>images/156/72/449419.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15672</td>\n",
       "      <td>200223</td>\n",
       "      <td>200223</td>\n",
       "      <td>1</td>\n",
       "      <td>Lecythidaceae</td>\n",
       "      <td>Lecythis</td>\n",
       "      <td>Lecythis retusa Spruce ex O.Berg</td>\n",
       "      <td>images/156/72/200223.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15672</td>\n",
       "      <td>5327</td>\n",
       "      <td>5327</td>\n",
       "      <td>1</td>\n",
       "      <td>Lecythidaceae</td>\n",
       "      <td>Lecythis</td>\n",
       "      <td>Lecythis retusa Spruce ex O.Berg</td>\n",
       "      <td>images/156/72/5327.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id      id  image_id  region_id         family     genus  \\\n",
       "0        15672  354106    354106          1  Lecythidaceae  Lecythis   \n",
       "1        15672  545181    545181          1  Lecythidaceae  Lecythis   \n",
       "2        15672  449419    449419          1  Lecythidaceae  Lecythis   \n",
       "3        15672  200223    200223          1  Lecythidaceae  Lecythis   \n",
       "4        15672    5327      5327          1  Lecythidaceae  Lecythis   \n",
       "\n",
       "                      category_name                 file_name  height  \\\n",
       "0  Lecythis retusa Spruce ex O.Berg  images/156/72/354106.jpg    1000   \n",
       "1  Lecythis retusa Spruce ex O.Berg  images/156/72/545181.jpg    1000   \n",
       "2  Lecythis retusa Spruce ex O.Berg  images/156/72/449419.jpg    1000   \n",
       "3  Lecythis retusa Spruce ex O.Berg  images/156/72/200223.jpg    1000   \n",
       "4  Lecythis retusa Spruce ex O.Berg    images/156/72/5327.jpg    1000   \n",
       "\n",
       "   license  width    region_name  \n",
       "0        1    661  South America  \n",
       "1        1    661  South America  \n",
       "2        1    662  South America  \n",
       "3        1    661  South America  \n",
       "4        1    661  South America  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_metadata_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    test_metadata_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'info', 'licenses'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metadata_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(test_metadata_json['images'])\n",
    "\n",
    "test_data = test_data.astype({'height': 'int32',\n",
    "                              'id': 'int32',\n",
    "                              'license': 'int32',\n",
    "                              'width': 'int32'})\n",
    "\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1030747 validated image filenames.\n",
      "Found 1030747 validated image filenames.\n",
      "Found 138292 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen_without_augmentation = ImageDataGenerator(rescale=1./255)\n",
    "datagen_with_augmentation = ImageDataGenerator(rescale=1./255, \n",
    "                                               featurewise_center=False,\n",
    "                                               samplewise_center=False,\n",
    "                                               featurewise_std_normalization=False,\n",
    "                                               samplewise_std_normalization=False,\n",
    "                                               zca_whitening=False,\n",
    "                                               rotation_range = 10,\n",
    "                                               zoom_range = 0.1,\n",
    "                                               width_shift_range=0.1,\n",
    "                                               height_shift_range=0.1,\n",
    "                                               horizontal_flip=True,\n",
    "                                               vertical_flip=False)\n",
    "\n",
    "train_datagen = datagen_with_augmentation.flow_from_dataframe(dataframe=train_data, \n",
    "                                                                 directory=train_images_dir, \n",
    "                                                                 x_col='file_name', \n",
    "                                                                 y_col='category_id',\n",
    "                                                                 class_mode=\"raw\",\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 color_mode = 'rgb',\n",
    "                                                                 target_size=(img_height,img_width)\n",
    "                                                             )\n",
    "\n",
    "val_datagen = datagen_without_augmentation.flow_from_dataframe(dataframe=train_data, \n",
    "                                                                 directory=train_images_dir, \n",
    "                                                                 x_col='file_name', \n",
    "                                                                 y_col='category_id',\n",
    "                                                                 class_mode=\"raw\",\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 color_mode = 'rgb',\n",
    "                                                                 target_size=(img_height,img_width))\n",
    "\n",
    "test_datagen = datagen_without_augmentation.flow_from_dataframe(dataframe=test_data,\n",
    "                                                              directory=test_images_dir,\n",
    "                                                               x_col='file_name',\n",
    "                                                               color_mode = 'rgb',\n",
    "                                                               class_mode=None,\n",
    "                                                               target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_wrapper(generator, num_of_classes):\n",
    "    for (X_vals, y_vals) in generator:\n",
    "        Y_categorical = to_categorical(y_vals, num_classes=num_of_classes)\n",
    "        \n",
    "        yield (X_vals, Y_categorical)        \n",
    "        \n",
    "train_datagen_wrapper = generator_wrapper(train_datagen, num_classes)\n",
    "val_datagen_wrapper = generator_wrapper(val_datagen, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=5, activation='relu', input_shape=(img_height, img_width, 3), padding='Same', strides=2))\n",
    "model.add(Conv2D(64, kernel_size=5, activation='relu', padding='Same', strides=2))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', padding='Same', strides=2))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', padding='Same', strides=2))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes / 100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d5a0151d2111>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2005 steps, validate for 2005 steps\n",
      "Epoch 1/2\n",
      "2005/2005 [==============================] - 4742s 2s/step - loss: 9.8509 - accuracy: 0.0013 - val_loss: 9.6599 - val_accuracy: 0.0019\n",
      "Epoch 2/2\n",
      "2005/2005 [==============================] - 4612s 2s/step - loss: 9.6441 - accuracy: 0.0017 - val_loss: 9.5850 - val_accuracy: 0.0018\n",
      "WARNING:tensorflow:From /home/arthur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cnn_model.h2/assets\n",
      "\n",
      "Learning took 9357.211953639984\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit_generator(train_datagen_wrapper,\n",
    "                              epochs=epochs_num,\n",
    "                              validation_data=val_datagen_wrapper,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_steps=steps_per_epoch)\n",
    " \n",
    "\n",
    "model.save('cnn_model.h2')\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nLearning took {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames.\n",
      "WARNING:tensorflow:From <ipython-input-16-0522266a8727>:15: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "4322/4322 [==============================] - 3931s 910ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "test_datagen_2 = ImageDataGenerator(featurewise_center=False,\n",
    "                                    featurewise_std_normalization=False)\n",
    "\n",
    "\n",
    "generator = test_datagen_2.flow_from_dataframe(\n",
    "        dataframe = test_data.iloc[:1000], #Limiting the test to the first 10,000 items\n",
    "        directory = test_images_dir,\n",
    "        x_col = 'file_name',\n",
    "        target_size=(120, 120),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)\n",
    "\n",
    "category = model.predict_generator(test_datagen, verbose=1)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104891</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18029</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35151</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124144</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24649</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138287</th>\n",
       "      <td>32738</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138288</th>\n",
       "      <td>16804</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138289</th>\n",
       "      <td>113662</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138290</th>\n",
       "      <td>86100</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138291</th>\n",
       "      <td>28731</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Predicted\n",
       "0       104891      23718\n",
       "1        18029      23718\n",
       "2        35151      23718\n",
       "3       124144      23718\n",
       "4        24649      23718\n",
       "...        ...        ...\n",
       "138287   32738      23718\n",
       "138288   16804      23718\n",
       "138289  113662      23718\n",
       "138290   86100      23718\n",
       "138291   28731      23718\n",
       "\n",
       "[138292 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "#display(test_data)\n",
    "sub['Id'] = test_data.id\n",
    "sub['Id'] = sub['Id'].astype('int32')\n",
    "sub['Predicted'] = np.concatenate([np.argmax(category, axis=1), 23718*np.ones((len(test_data.id)-len(category)))], axis=0)\n",
    "sub['Predicted'] = sub['Predicted'].astype('int32')\n",
    "display(sub)\n",
    "sub.to_csv('category_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
